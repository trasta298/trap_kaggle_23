{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = {\n",
    "    'random_state': 421,\n",
    "    'is_square': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "anime_data = pd.read_csv('anime.csv')\n",
    "profile_data = pd.read_csv('profile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_train = train_data.isnull().sum()\n",
    "missing_values_test = test_data.isnull().sum()\n",
    "missing_values_anime = anime_data.isnull().sum()\n",
    "missing_values_profile = profile_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values for anime.csv\n",
    "anime_data['synopsis'].fillna('', inplace=True)\n",
    "anime_data['episodes'].fillna(anime_data['episodes'].median(), inplace=True)\n",
    "\n",
    "# ranked は start_year=2020 または genre に Hentai が含まれている場合は全体の平均値、それ以外は max + 1 で埋める\n",
    "anime_data['ranked'].fillna(anime_data[anime_data['start_year'] == 2020]['ranked'].mean(), inplace=True)\n",
    "anime_data['ranked'].fillna(anime_data[anime_data['genre'].str.contains('Hentai')]['ranked'].mean(), inplace=True)\n",
    "anime_data['ranked'].fillna(anime_data['ranked'].max() + 1, inplace=True)\n",
    "\n",
    "# Filling missing values for profile.csv\n",
    "profile_data['gender'].fillna('Unknown', inplace=True)\n",
    "anime_data.isnull().sum(), profile_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Converting birthday to age\n",
    "def calculate_age(birthday):\n",
    "    try:\n",
    "        birth_date = datetime.strptime(birthday, '%b %d, %Y')\n",
    "        return 2023 - birth_date.year\n",
    "    except:\n",
    "        try:\n",
    "            birth_date = datetime.strptime(birthday, '%Y')\n",
    "            return 2023 - birth_date.year\n",
    "        except:\n",
    "            try:\n",
    "                birth_date = datetime.strptime(birthday, '%m, %Y')\n",
    "                return 2023 - birth_date.year\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "profile_data['age'] = profile_data['birthday'].apply(calculate_age)\n",
    "\n",
    "profile_data.drop('birthday', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値を平均値で埋める\n",
    "profile_data['age'].fillna(profile_data['age'].mean(), inplace=True)\n",
    "\n",
    "# 10以下、80以上の値を平均値で埋める\n",
    "profile_data.loc[profile_data['age'] < 10, 'age'] = profile_data['age'].mean()\n",
    "profile_data.loc[profile_data['age'] > 80, 'age'] = profile_data['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_yearが欠損値のデータのうち、start_monthが欠損値でないデータは start_year = start_month とする\n",
    "anime_data.loc[anime_data['start_year'].isnull() & anime_data['start_month'].notnull(), 'start_year'] = anime_data['start_month']\n",
    "\n",
    "# start_yearが欠損値のidを持っておく\n",
    "missing_start_year_ids = anime_data.loc[anime_data['start_year'].isnull(), 'id']\n",
    "\n",
    "anime_data_sorted = anime_data.sort_values('members', ascending=False)\n",
    "# start_yearでソートしたものを作成\n",
    "anime_data_sorted_by_start_year = anime_data.sort_values('start_year', ascending=False)\n",
    "\n",
    "# start_yearの欠損値を、start_yearの大きさの順位が member の値の順位の数字 と同じ値の start_year で埋める\n",
    "i = 0\n",
    "for row in anime_data_sorted.itertuples():\n",
    "    if pd.isna(row.start_year):\n",
    "        anime_data.loc[anime_data['id'] == row.id, 'start_year'] = anime_data_sorted_by_start_year.iloc[i]['start_year']\n",
    "    i += 1\n",
    "\n",
    "# start_yearの欠損値を1940で埋める\n",
    "anime_data['start_year'].fillna(1940, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titleに Ⅱ, Ⅲ, Ⅳが含まれる、または、titleに \"Season\" が含まれる、 2nd, 3rd, 4th が含まれる、または、titleの末尾に 2, 3, 4 が含まれるものは 1 にする\n",
    "season_symbols = ['Ⅱ', 'Ⅲ', 'Ⅳ', 'II', 'III', 'IV', '2nd', '3rd', '4th', ' Season', ' season']\n",
    "anime_data['season'] = anime_data['title'].apply(lambda x: 1 if any(s in x for s in season_symbols) or any(x.endswith(s) for s in ['2', '3', '4']) else 0)\n",
    "\n",
    "# titleに Lupin が含まれるものは 0 にする\n",
    "anime_data['season'] = anime_data.apply(lambda x: 0 if 'Lupin' in x['title'] else x['season'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genreをone-hotエンコーディング genre_〇〇 にする\n",
    "import ast\n",
    "anime_data['genre'] = anime_data['genre'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "genres = set()\n",
    "for row in anime_data.itertuples():\n",
    "    if isinstance(row.genre, list):\n",
    "        for genre in row.genre:\n",
    "            genres.add(genre)\n",
    "\n",
    "for genre in genres:\n",
    "    anime_data['genre_' + genre] = anime_data['genre'].apply(lambda x: 1 if isinstance(x, list) and genre in x else 0)\n",
    "\n",
    "anime_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重複データの削除\n",
    "anime_data.drop_duplicates(subset=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data(anime_id) と anime_data(id) を結合 left outer join\n",
    "train_data_merged = pd.merge(train_data, anime_data, left_on='anime_id', right_on='id', how='left')\n",
    "test_data_merged = pd.merge(test_data, anime_data, left_on='anime_id', right_on='id', how='left')\n",
    "\n",
    "# start_day, start_month, end_month, end_day, end_year を削除\n",
    "train_data_merged.drop(columns=['start_day', 'start_month', 'end_month', 'end_day', 'end_year'], inplace=True)\n",
    "test_data_merged.drop(columns=['start_day', 'start_month', 'end_month', 'end_day', 'end_year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoreが10より大きいものを10にする\n",
    "train_data_merged.loc[train_data_merged['score'] > 10, 'score'] = 10\n",
    "\n",
    "# scoreが1より小さいものを1にする\n",
    "train_data_merged.loc[train_data_merged['score'] < 1, 'score'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# season ごとに score の分布を可視化\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.boxplot(x='season', y='score', data=train_data_merged)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data(user) と profile_data(user) を結合\n",
    "train_data_merged = pd.merge(train_data_merged, profile_data, left_on='user', right_on='user', how='left')\n",
    "test_data_merged = pd.merge(test_data_merged, profile_data, left_on='user', right_on='user', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# その行以外のuserがつけたscoreの数をカウントして、その値をカラムにする userscore_1 ~ userscore_10\n",
    "# 先にmapを作る\n",
    "from collections import defaultdict\n",
    "\n",
    "user_score_map = defaultdict(lambda: defaultdict(int))\n",
    "for row in train_data_merged.itertuples():\n",
    "    user_score_map[row.user][row.score] += 1\n",
    "\n",
    "# mapを使ってカラムを作る\n",
    "for i in range(1, 11):\n",
    "    train_data_merged['userscore_' + str(i)] = train_data_merged.apply(lambda x: user_score_map[x['user']][i] if i != x['score'] else user_score_map[x['user']][i] - 1, axis=1)\n",
    "    test_data_merged['userscore_' + str(i)] = test_data_merged.apply(lambda x: user_score_map[x['user']][i], axis=1)\n",
    "\n",
    "\n",
    "# # scoreの平均値を計算\n",
    "# score_mean = train_data_merged['score'].mean()\n",
    "\n",
    "# # その行以外のuserがつけたscoreの平均値をカラムにする userscore_mean\n",
    "# # 先にmapを作る\n",
    "# user_score_mean_map = defaultdict(lambda: defaultdict(int))\n",
    "# for row in train_data_merged.itertuples():\n",
    "#     user_score_mean_map[row.user]['score'] += row.score\n",
    "#     user_score_mean_map[row.user]['count'] += 1\n",
    "\n",
    "# # mapを使ってカラムを作る\n",
    "# train_data_merged['userscore_mean'] = train_data_merged.apply(lambda x: (user_score_mean_map[x['user']]['score'] - x['score']) / (user_score_mean_map[x['user']]['count'] - 1 if user_score_mean_map[x['user']]['count'] > 1 else score_mean), axis=1)\n",
    "# test_data_merged['userscore_mean'] = test_data_merged.apply(lambda x: user_score_mean_map[x['user']]['score'] / user_score_mean_map[x['user']]['count'] if user_score_mean_map[x['user']]['count'] > 0 else score_mean, axis=1)\n",
    "\n",
    "\n",
    "# # score_1 ~ score_10 カラムを 行ごとに正規化\n",
    "# columns_to_normalize = [f'userscore_{i}' for i in range(1, 11)]\n",
    "# train_data_merged[columns_to_normalize] = train_data_merged[columns_to_normalize].apply(lambda x: x / x.sum() if x.sum() != 0 else x, axis=1)\n",
    "# test_data_merged[columns_to_normalize] = test_data_merged[columns_to_normalize].apply(lambda x: x / x.sum() if x.sum() != 0 else x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# その行以外のuser がつけた score の平均値を取って、userscore という名前のカラムに追加\n",
    "# train_data_merged['userscore'] = train_data_merged.groupby('user')['score'].transform(lambda x: (x.sum() - x) / (x.count() - 1) if x.count() > 1 else None)\n",
    "# test_data_merged['userscore'] = train_data_merged.groupby('user')['score'].transform(lambda x: x.mean() if x.count() > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anime ごとに score の平均値を取って、animescore という名前のカラムに追加\n",
    "train_data_merged['animescore'] = train_data_merged.groupby('anime_id')['score'].transform(lambda x: (x.sum() - x) / (x.count() - 1) if x.count() > 1 else None)\n",
    "test_data_merged['animescore'] = train_data_merged.groupby('anime_id')['score'].transform(lambda x: x.mean() if x.count() > 0 else None)\n",
    "\n",
    "# animescore が欠損値のものは、平均値で埋める\n",
    "train_data_merged['animescore'].fillna(train_data_merged['score'].mean(), inplace=True)\n",
    "test_data_merged['animescore'].fillna(train_data_merged['score'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userscoreの欠損値を、animescoreと全scoreの平均のの相乗平均で埋める\n",
    "# av_score = train_data_merged['score'].mean()\n",
    "# train_data_merged['userscore'].fillna((train_data_merged['animescore'] * av_score) ** 0.5, inplace=True)\n",
    "# test_data_merged['userscore'].fillna((test_data_merged['animescore'] * av_score) ** 0.5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_len を追加\n",
    "train_data_merged['text_len'] = train_data_merged['text'].apply(lambda x: len(x.replace(' ', '').replace('\\n', '')))\n",
    "\n",
    "# その行以外のuserごとの平均 text_len を追加\n",
    "# train_data_merged['user_text_len'] = train_data_merged.groupby('user')['text_len'].transform(lambda x: (x.sum() - x) / (x.count() - 1) if x.count() > 1 else None)\n",
    "# test_data_merged['user_text_len'] = train_data_merged.groupby('user')['text_len'].transform(lambda x: x.mean())\n",
    "\n",
    "# user_text_lenが0のものについては全体の平均で埋める\n",
    "# av_text_len = train_data_merged['text_len'].mean()\n",
    "# train_data_merged['user_text_len'].fillna(av_text_len, inplace=True)\n",
    "# test_data_merged['user_text_len'].fillna(av_text_len, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# gender の Non-Binary を Unknown にする\n",
    "train_data_merged = train_data_merged.replace('Non-Binary', 'Unknown')\n",
    "test_data_merged = test_data_merged.replace('Non-Binary', 'Unknown')\n",
    "\n",
    "# genderをOne-Hotエンコーディング\n",
    "gender_encoder = OneHotEncoder()\n",
    "gender_one_hot = gender_encoder.fit_transform(train_data_merged[['gender']]).toarray()  # type: ignore\n",
    "gender_labels = gender_encoder.get_feature_names_out(['gender'])\n",
    "for i, label in enumerate(gender_labels):\n",
    "    train_data_merged[label] = gender_one_hot[:, i]\n",
    "\n",
    "gender_one_hot_test = gender_encoder.transform(test_data_merged[['gender']]).toarray()  # type: ignore\n",
    "for i, label in enumerate(gender_labels):\n",
    "    test_data_merged[label] = gender_one_hot_test[:, i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender_Femaleの合計\n",
    "train_data_merged['gender_Male'].sum(), train_data_merged['gender_Female'].sum(), train_data_merged['gender_Unknown'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "genderを二値分類で推測しようのコーナー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# genderが Male or Female のもののみを残す\n",
    "train_valid = train_data_merged[(train_data_merged['gender_Male'] == 1) | train_data_merged['gender_Female'] == 1]\n",
    "train_invalid = train_data_merged[train_data_merged['gender_Unknown'] == 1]\n",
    "\n",
    "genre_columns = [col for col in train_valid.columns if 'genre_' in col]\n",
    "\n",
    "# genre_{任意のジャンル}カラムにscoreを掛ける\n",
    "for genre in genre_columns:\n",
    "    train_valid[genre] *= train_valid['score']\n",
    "    train_invalid[genre] *= train_invalid['score']\n",
    "\n",
    "# userごとにジャンルカラムを合計し、1に正規化\n",
    "train_valid_grouped = train_valid.groupby('user')[genre_columns].sum()\n",
    "train_valid_grouped = train_valid_grouped.div(train_valid_grouped.sum(axis=1), axis=0)\n",
    "train_invalid_grouped = train_invalid.groupby('user')[genre_columns].sum()\n",
    "train_invalid_grouped = train_invalid_grouped.div(train_invalid_grouped.sum(axis=1), axis=0)\n",
    "\n",
    "# gender, userカラムを追加\n",
    "train_valid_grouped['gender'] = train_valid.groupby('user')['gender'].first()\n",
    "train_valid_grouped['user'] = train_valid_grouped.index\n",
    "train_invalid_grouped['user'] = train_invalid_grouped.index\n",
    "\n",
    "# Male 0 Female 1\n",
    "train_valid_grouped['gender'] = train_valid_grouped['gender'].map({'Male': 0, 'Female': 1})\n",
    "train_valid_grouped = train_valid_grouped.reset_index(drop=True)\n",
    "train_invalid_grouped = train_invalid_grouped.reset_index(drop=True)\n",
    "\n",
    "x_train = train_valid_grouped.drop(columns=['gender', 'user'])\n",
    "y_train = train_valid_grouped['gender']\n",
    "\n",
    "x_test = train_invalid_grouped.drop(columns=['user'])\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# パラメータの設定\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'verbose': -1,\n",
    "    'boosting': 'gbdt',\n",
    "    'early_stopping_round': 20,\n",
    "    'n_estimators': 10000, \n",
    "    'learning_rate': 0.05,\n",
    "    'random_state': seeds['random_state'],\n",
    "}\n",
    "# 10分割のクロスバリデーション\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=seeds['random_state'])\n",
    "\n",
    "# 各分割での評価スコアを保存\n",
    "scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(x_train):\n",
    "    x_train_fold, x_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    bst = lgb.LGBMRegressor(**params)\n",
    "    bst.fit(x_train_fold, y_train_fold, eval_set=[(x_train_fold, y_train_fold), (x_val_fold, y_val_fold)])\n",
    "\n",
    "    # 予測\n",
    "    y_prod = bst.predict(x_val_fold)\n",
    "    y_pred = np.round(y_prod)  # type: ignore\n",
    "\n",
    "    # 評価\n",
    "    y_pred_tmp = np.where(y_prod <= 0.2, 0, np.where(y_prod >= 0.8, 1, 2))  # type: ignore\n",
    "    index_to_remove = np.where(y_pred_tmp == 2)\n",
    "    y_pred_tmp = np.delete(y_pred_tmp, index_to_remove)\n",
    "    y_val_fold_tmp = np.delete(y_val_fold, index_to_remove)\n",
    "\n",
    "    acc = accuracy_score(y_val_fold_tmp, y_pred_tmp)  # type: ignore\n",
    "    scores.append(acc)\n",
    "    print(f'Accuracy: {acc}')\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_val_fold, y_pred)\n",
    "    aucval = auc(fpr, tpr)\n",
    "    print(f'AUC: {aucval}')\n",
    "\n",
    "    # ROC曲線をプロット\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%aucval)\n",
    "    plt.legend()\n",
    "    plt.title('ROC curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.grid(True)\n",
    "\n",
    "# 全体の平均スコア\n",
    "mean_score = np.mean(scores)\n",
    "print(f'Mean Accuracy: {mean_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important_features の上位10個を表示\n",
    "importance = pd.DataFrame(bst.feature_importances_, index=x_train.columns, columns=['importance'])\n",
    "importance.sort_values('importance', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = bst.predict(x_test)\n",
    "# 0.3以下のものを0、0.7以上のものを1、それ以外を2にする\n",
    "y_pred_test = np.where(y_pred_test < 0.4, 0, np.where(y_pred_test >= 0.6, 1, 2))  # type: ignore\n",
    "\n",
    "train_invalid_grouped['gender'] = y_pred_test\n",
    "# userとgenderの対応を示したmapを作成\n",
    "user_gender_map = pd.Series(train_invalid_grouped['gender'].values, index=train_invalid_grouped['user']).to_dict()\n",
    "\n",
    "gender_map = {\n",
    "    0: 'Male', 1: 'Female', 2: 'Unknown'\n",
    "}\n",
    "\n",
    "# gender_Unknownが1で、user_gender_mapに存在するuserに対して操作を行う\n",
    "for idx, row in train_data_merged[train_data_merged['gender_Unknown'] == 1].iterrows():\n",
    "    user_value = row['user']\n",
    "    gender_value = user_gender_map.get(user_value)\n",
    "    if gender_value is not None:\n",
    "        train_data_merged.loc[idx, 'gender_Male'] = 1 if gender_value == 0 else 0  # type: ignore\n",
    "        train_data_merged.loc[idx, 'gender_Female'] = 1 if gender_value == 1 else 0  # type: ignore\n",
    "        train_data_merged.loc[idx, 'gender_Unknown'] = 1 if gender_value == 2 else 0  # type: ignore\n",
    "        train_data_merged.loc[idx, 'gender'] = gender_map[gender_value]  # type: ignore\n",
    "\n",
    "for idx, row in test_data_merged[test_data_merged['gender_Unknown'] == 1].iterrows():\n",
    "    user_value = row['user']\n",
    "    gender_value = user_gender_map.get(user_value)\n",
    "    if gender_value is not None:\n",
    "        test_data_merged.loc[idx, 'gender_Male'] = 1 if gender_value == 0 else 0  # type: ignore\n",
    "        test_data_merged.loc[idx, 'gender_Female'] = 1 if gender_value == 1 else 0  # type: ignore\n",
    "        test_data_merged.loc[idx, 'gender_Unknown'] = 1 if gender_value == 2 else 0  # type: ignore\n",
    "        test_data_merged.loc[idx, 'gender'] = gender_map[gender_value]  # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender_Femaleの合計\n",
    "train_data_merged['gender_Male'].sum(), train_data_merged['gender_Female'].sum(), train_data_merged['gender_Unknown'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender_ から始まるカラムと genre_ から始まるカラムを掛け合わせる\n",
    "for gender_col in [col for col in train_data_merged.columns if col.startswith('gender_')]:\n",
    "    for genre_col in [col for col in train_data_merged.columns if col.startswith('genre_')]:\n",
    "        gender = gender_col.split('_')[1]\n",
    "        genre = genre_col.split('_')[1]\n",
    "        new_col_name = f'gen_{genre}_{gender}'\n",
    "        train_data_merged[new_col_name] = train_data_merged[gender_col] * train_data_merged[genre_col]\n",
    "\n",
    "for gender_col in [col for col in test_data_merged.columns if col.startswith('gender_')]:\n",
    "    for genre_col in [col for col in test_data_merged.columns if col.startswith('genre_')]:\n",
    "        gender = gender_col.split('_')[1]\n",
    "        genre = genre_col.split('_')[1]\n",
    "        new_col_name = f'gen_{genre}_{gender}'\n",
    "        test_data_merged[new_col_name] = test_data_merged[gender_col] * test_data_merged[genre_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_ から始まるカラムで合計が500以下のものを削除\n",
    "for col in [col for col in train_data_merged.columns if col.startswith('gen_')]:\n",
    "    if train_data_merged[col].sum() <= 500:\n",
    "        train_data_merged.drop(columns=[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_merged のカラムを確認\n",
    "print(train_data_merged.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight カラムを作成し、1で初期化\n",
    "train_data_merged['weight'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate features\n",
    "cat_cols = ['user', 'season']\n",
    "agg_cols = ['episodes', 'members', 'ranked', 'start_year', 'text_len']\n",
    "agg_types = ['mean', 'std', 'max', 'min', 'sum']\n",
    "\n",
    "for cat_col in cat_cols:\n",
    "    for agg_col in agg_cols:\n",
    "        for agg_type in agg_types:\n",
    "            if cat_col != agg_col:\n",
    "                new_col_name = 'agg_' + cat_col + '_' + agg_col + '_' + agg_type\n",
    "                temp = train_data_merged[[cat_col, agg_col]]\n",
    "                temp = temp.groupby([cat_col])[agg_col].agg([agg_type]).reset_index().rename(columns={agg_type: new_col_name})\n",
    "                temp.index = list(temp[cat_col])  # type: ignore\n",
    "                temp = temp[new_col_name].to_dict()\n",
    "                train_data_merged[new_col_name] = train_data_merged[cat_col].map(temp)\n",
    "                test_data_merged[new_col_name] = test_data_merged[cat_col].map(temp)\n",
    "\n",
    "# aggregate features\n",
    "# cat_cols = ['anime_id']\n",
    "# agg_cols = ['text_len', 'age']\n",
    "# agg_cols += [col for col in train_data_merged.columns if col.startswith('gender_')]\n",
    "# agg_types = ['mean', 'std', 'max', 'min', 'sum']\n",
    "\n",
    "# for cat_col in cat_cols:\n",
    "#     for agg_col in agg_cols:\n",
    "#         for agg_type in agg_types:\n",
    "#             if cat_col != agg_col:\n",
    "#                 new_col_name = 'agg_' + cat_col + '_' + agg_col + '_' + agg_type\n",
    "#                 temp = train_data_merged[[cat_col, agg_col]]\n",
    "#                 temp = temp.groupby([cat_col])[agg_col].agg([agg_type]).reset_index().rename(columns={agg_type: new_col_name})\n",
    "#                 temp.index = list(temp[cat_col])  # type: ignore\n",
    "#                 temp = temp[new_col_name].to_dict()\n",
    "#                 train_data_merged[new_col_name] = train_data_merged[cat_col].map(temp)\n",
    "#                 test_data_merged[new_col_name] = test_data_merged[cat_col].map(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['episodes', 'members', 'ranked', 'start_year', 'season', 'genre_*', 'gender', 'age'] カラムを特徴量として摘出する\n",
    "correct_features = ['episodes', 'members', 'ranked', 'start_year', 'age']\n",
    "correct_features.extend([col for col in train_data_merged.columns if col.startswith('gen_') and 'Unknown' not in col])\n",
    "correct_features.extend([col for col in train_data_merged.columns if col.startswith('userscore_')])\n",
    "correct_features.extend([col for col in train_data_merged.columns if col.startswith('agg_') and 'Unknown' not in col])\n",
    "# correct_features.extend([col for col in train_data_merged.columns if col.startswith('umap_vector_')])\n",
    "\n",
    "x_train = train_data_merged[correct_features + ['weight']]\n",
    "x_test = test_data_merged[correct_features]\n",
    "\n",
    "# score を正解データとして摘出する\n",
    "y_train = train_data_merged['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# パラメータの設定\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mse',\n",
    "    'verbose': -1,\n",
    "    'early_stopping_round': 20,\n",
    "    'n_estimators': 10000, \n",
    "    'boosting_type': 'gbdt',  # default = 'gbdt'\n",
    "    'num_leaves': 127,         # default = 31,\n",
    "    'learning_rate': 0.01,    # default = 0.1\n",
    "    'feature_fraction': 0.8,  # default = 1.0\n",
    "    'bagging_freq': 1,        # default = 0\n",
    "    'bagging_fraction': 0.8,  # default = 1.0\n",
    "    'max_depth': 12,\n",
    "    'random_state': seeds['random_state'],\n",
    "}\n",
    "# 10分割のクロスバリデーション\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=seeds['random_state'])\n",
    "\n",
    "# 各分割での評価スコアを保存\n",
    "scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(x_train):\n",
    "    x_train_fold, x_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    sample_weight = x_train_fold['weight']\n",
    "    x_train_fold = x_train_fold.drop(columns=['weight'])\n",
    "    x_val_fold = x_val_fold.drop(columns=['weight'])\n",
    "\n",
    "    if seeds['is_square']:\n",
    "        # 11から引いた上で平方根をとる\n",
    "        y_train_fold = np.sqrt(11 - y_train_fold)  # type: ignore\n",
    "        y_val_fold = np.sqrt(11 - y_val_fold)  # type: ignore\n",
    "\n",
    "    bst = lgb.LGBMRegressor(**params)\n",
    "    bst.fit(x_train_fold, y_train_fold, eval_set=[(x_train_fold, y_train_fold), (x_val_fold, y_val_fold)], sample_weight=sample_weight)  # type: ignore\n",
    "\n",
    "    # 予測\n",
    "    y_pred = bst.predict(x_val_fold)\n",
    "\n",
    "    if seeds['is_square']:\n",
    "        # (11から引いた上で平方根をとる)の逆変換\n",
    "        y_pred = 11 - np.square(y_pred)  # type: ignore\n",
    "        y_val_fold = 11 - np.square(y_val_fold)  # type: ignore\n",
    "\n",
    "    # 評価\n",
    "    mse = mean_squared_error(y_val_fold, y_pred)  # type: ignore\n",
    "    scores.append(mse)\n",
    "    print(f'Mean Squared Error for fold: {mse}')\n",
    "\n",
    "    lgb.plot_metric(bst)\n",
    "    plt.show()\n",
    "\n",
    "# 全体の平均スコア\n",
    "mean_score = np.mean(scores)\n",
    "print(f'Mean Squared Error for 5-folds CV: {mean_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important_features の上位10個を表示\n",
    "importance = pd.DataFrame(bst.feature_importances_, index=x_train.drop(columns=['weight']).columns, columns=['importance'])\n",
    "importance.sort_values('importance', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = bst.predict(x_test)\n",
    "\n",
    "if seeds['is_square']:\n",
    "    # (11から引いた上で平方根をとる)の逆変換\n",
    "    y_pred_test = 11 - np.square(y_pred_test)  # type: ignore\n",
    "\n",
    "# sample_submission.csv を読み込む\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# predicted_scores を sample_submission の score に代入\n",
    "sample_submission['score'] = y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission のスコア分布を確認\n",
    "sample_submission['score'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission のスコアで10より大きいものを10にする\n",
    "sample_submission.loc[sample_submission['score'] > 10, 'score'] = 10\n",
    "# sample_submission のスコアで1より小さいものを1にする\n",
    "sample_submission.loc[sample_submission['score'] < 1, 'score'] = 1\n",
    "\n",
    "# sample_submission を出力\n",
    "sample_submission.to_csv('submission421.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
